# Proyecto

Contruir un pipeline de MLops que:
1. Ingeste datos desde una API externa (1 petici√≥n = 1 ejecuci√≥n).
2. Entrene un modelo y registre m√©tricas/artefactos en MLflow.
3. Sirva el modelo en FastAPI para hacer inferencias en l√≠nea.
4. (Bono) Exponga una UI en Streamlit para interactuar con el modelo f√°cilmente.

## Servicios principales

1. Airflow: Orquesta DAGs que hacen fetch ‚Üí preprocess ‚Üí train ‚Üí log ‚Üí register.
Cada ejecuci√≥n del DAG es una sola petici√≥n a la API de datos.
Te asegura reproducibilidad y trazabilidad.

2. MLflow: Registra par√°metros, m√©tricas y artefactos de cada entrenamiento.
- Usa MySQL para guardar metadatos (runs, metrics, params).
- Usa MinIO como artifact store (modelos, plots, datasets).

3. MySQL: Base de datos para los metadatos de MLflow.

4. MinIO: Almac√©n de objetos estilo S3 para guardar los artefactos de MLflow.

5. FastAPI:
- API de inferencia: carga el √∫ltimo modelo de MLflow Registry.
- Expone /predict y /health.

6. Streamlit (bono) üé®
- Interfaz gr√°fica simple en puerto 8503.
- Consume el endpoint /predict de FastAPI y muestra resultados.

```scss
    [Airflow DAG]
 fetch ‚Üí preprocess ‚Üí train ‚Üí log_to_mlflow ‚Üí register
                 ‚îÇ
                 ‚ñº
          [MLflow Tracking]
         ‚îú‚îÄ MySQL (metadatos)
         ‚îî‚îÄ MinIO (artefactos)
                 ‚îÇ
                 ‚ñº
          [Model Registry]
                 ‚îÇ
                 ‚ñº
        [FastAPI Inference API]
                 ‚îÇ
                 ‚ñº
      [Streamlit UI] (opcional/bono)

```



```text
mlops-p2/
‚îú‚îÄ airflow/              # Orquestaci√≥n de pipelines
‚îÇ  ‚îú‚îÄ dags/              # DAGs de Airflow
‚îÇ  ‚îú‚îÄ logs/              # Logs de ejecuci√≥n
‚îÇ  ‚îú‚îÄ plugins/           # Plugins adicionales
‚îÇ  ‚îî‚îÄ requirements.txt   # Dependencias extra de Airflow
‚îÇ
‚îú‚îÄ fastapi/              # Servicio de inferencia
‚îÇ  ‚îú‚îÄ app.py             # API FastAPI (serving)
‚îÇ  ‚îî‚îÄ requirements.txt   # Dependencias de FastAPI
‚îÇ
‚îú‚îÄ mlflow/               # Imagen/servidor de MLflow
‚îÇ  ‚îî‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ configs/              # Configuraci√≥n de servicios
‚îÇ  ‚îú‚îÄ mysql-init.sql     # Script de inicializaci√≥n MySQL (DB mlflow, usuario, permisos)
‚îÇ  ‚îî‚îÄ .env               # (opcional) variables de entorno locales
‚îÇ
‚îú‚îÄ scripts/              # Scripts utilitarios
‚îÇ  ‚îú‚îÄ bootstrap_minio.sh # Crea bucket inicial en MinIO (mlflow)
‚îÇ  ‚îî‚îÄ promote_latest.py  # Promueve mejor modelo en el Registry
‚îÇ
‚îú‚îÄ mysql_data/           # Datos persistentes de MySQL (volumen)
‚îÇ
‚îú‚îÄ ui/                   # (BONO) Interfaz Streamlit/Gradio
‚îÇ  ‚îî‚îÄ app.py
‚îÇ
‚îú‚îÄ docker-compose.yml    # Orquestaci√≥n de servicios en local
‚îî‚îÄ README.md             # Documentaci√≥n del proyecto

```
üìå Plan de ejecuci√≥n (paso a paso)
Preparaci√≥n (PASO 0‚Äì1)
Instalar Docker, crear estructura del repo, escribir docker-compose.yml.
Infra base (PASO 2)
Levantar MySQL, MinIO, MLflow, Airflow y FastAPI.
Validar que todas las UIs responden en localhost.
Pipeline en Airflow (PASO 3)
Crear DAG que ingesta, entrena y registra modelos en MLflow.
Serving en FastAPI (PASO 4)
Conectar FastAPI al Model Registry y servir el √∫ltimo modelo en Production.
UI en Streamlit (PASO 5 ‚Äî bono)
Montar una app simple que consuma el endpoint de FastAPI.

Validaci√≥n de API:

```python
import requests
URL = "http://10.43.100.103:8080/data"

resp = requests.get(URL, params={"group_number": 1})
print("Status:", resp.status_code)
print("Batch:", resp.json()["batch_number"])
print("Primeras filas:", resp.json()["data"][:2])
```

## PASO 0 - Prerrequisitos
Objetivo: Tener el ambiente local listo para correr los servicios con Docker y trabajar con Python.

1. Instalar Docker y Docker Compose
- Verifica versiones:
```bash
docker --version
docker compose version
```

2. Probar contenedores en tu m√°quina
```bash
docker run --rm hello-world
```

3. Python
```bash
python --version
```
4. Crear entorno virtual y instalaci√≥n de librerias para el proyecto
```bash
python -m venv venv
source venv/bin/activate
pip install requests
```
## PASO 1 - Estructura inicial del proyecto

Objetivo: Crear carpetas y archivos base del repo

```bash
mkdir -p Proyecto_MLOPS/{airflow/{dags,logs,plugins},fastapi,mlflow,configs,scripts,mysql_data,ui,data}
cd Proyecto_MLOPS
```

Esto crea:
airflow/ ‚Üí DAGs, logs, plugins.
fastapi/ ‚Üí API de inferencia.
mlflow/ ‚Üí imagen de MLflow.
configs/ ‚Üí config de MySQL, .envs.
scripts/ ‚Üí scripts utilitarios.
mysql_data/ ‚Üí datos persistentes de MySQL.
ui/ ‚Üí interfaz en Streamlit.
data/ ‚Üí donde guardaremos los batches acumulados.

2. Crear script de inicializaci√≥n de MySQL
Archivo: configs/mysql-init.sql

üßæ ¬øQu√© hace este script?
CREATE DATABASE IF NOT EXISTS mlflow ...;
Crea una base de datos llamada mlflow.
Esta BD es la que usar√° MLflow para guardar todos los metadatos de experimentos (runs, par√°metros, m√©tricas, rutas de artefactos).
El IF NOT EXISTS asegura que no d√© error si la BD ya existe.
CREATE USER IF NOT EXISTS 'mlflow'@'%' IDENTIFIED BY 'mlflow';
Crea un usuario en MySQL llamado mlflow con contrase√±a mlflow.
El @'%' significa que ese usuario puede conectarse desde cualquier host (en este caso, desde el contenedor de MLflow).
Igual que antes, con IF NOT EXISTS no se rompe si ya existe.
GRANT ALL PRIVILEGES ON mlflow.* TO 'mlflow'@'%';
Le da al usuario mlflow permisos completos sobre la base de datos mlflow.
Sin esto, MLflow no podr√≠a insertar ni leer metadatos.
FLUSH PRIVILEGES;
Le dice a MySQL que recargue la tabla de usuarios y permisos para aplicar los cambios.

3. Crear airflow/requirements.txt
apache-airflow-providers-http
apache-airflow-providers-mysql
requests
pandas
scikit-learn
mlflow
boto3

4. Crear fastapi/requirements.txt
fastapi
uvicorn
pydantic
mlflow
boto3
pandas
scikit-learn

5. Crear fastapi/app.py (servicio m√≠nimo)

üß© Explicaci√≥n general de fastapi/app.py
1. Arranca un servidor web con FastAPI
FastAPI(...) crea la aplicaci√≥n web.
Esta aplicaci√≥n es un servicio REST ‚Üí puedes consultarlo con GET /health o POST /predict.
Es el punto de entrada para consumir tu modelo desde afuera.
2. Define la estructura de los datos de entrada
La clase InputRow(BaseModel) describe qu√© variables debe enviar el usuario para predecir.
En este caso son las 12 features de los batches (todo excepto Cover_Type, que es la etiqueta).
FastAPI valida autom√°ticamente que los datos lleguen en el formato correcto (floats para num√©ricas, string para categor√≠as).
3. Configura la conexi√≥n a MLflow (placeholder)
Variables:
MLFLOW_TRACKING_URI: direcci√≥n del servidor MLflow.
MODEL_NAME: nombre del modelo en el Registry (ej: "cover_type_model").
MODEL_STAGE: stage del modelo que serviremos (ej: "Production").
Por ahora model = None ‚Üí significa que a√∫n no tenemos un modelo cargado.
M√°s adelante, cuando registremos un modelo en MLflow, este mismo c√≥digo sabr√° buscarlo y cargarlo autom√°ticamente.
4. Endpoints
GET /health
Devuelve {"status": "ok"}.
Sirve para verificar que el servicio est√° vivo (√∫til para monitoreo).
POST /predict
Recibe un JSON con las 12 features (ej: Elevation, Aspect, etc.).
Convierte los datos en un DataFrame de Pandas (porque as√≠ esperan la mayor√≠a de modelos en MLflow).
Si no hay modelo cargado ‚Üí devuelve "Modelo a√∫n no cargado".
Cuando haya modelo cargado ‚Üí ejecuta model.predict(...) y devuelve la clase predicha (Cover_Type).
üéØ En resumen
Este archivo es el servidor de predicciones.
Por ahora responde con un placeholder porque todav√≠a no entrenamos nada.
Pero ya est√° estructurado para que en cuanto registres tu primer modelo en MLflow, FastAPI lo sirva sin tener que modificar nada.
üëâ As√≠ cuando avancemos en los siguientes pasos (Airflow + MLflow), no tendremos que tocar FastAPI otra vez. Solo entrenamos, registramos el modelo como "cover_type_model", lo promovemos a "Production", ¬°y listo! FastAPI empezar√° a responder predicciones reales.

```python
from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
import mlflow
import os

# --------------------------------------------------
# Inicializaci√≥n de la app FastAPI
# --------------------------------------------------
app = FastAPI(
    title="MLOps P2 Serving",
    description="API para servir el modelo entrenado y registrado en MLflow",
    version="0.1.0"
)

# --------------------------------------------------
# Modelo de entrada (features reales del dataset)
# --------------------------------------------------
class InputRow(BaseModel):
    Elevation: float
    Aspect: float
    Slope: float
    Horizontal_Distance_To_Hydrology: float
    Vertical_Distance_To_Hydrology: float
    Horizontal_Distance_To_Roadways: float
    Hillshade_9am: float
    Hillshade_Noon: float
    Hillshade_3pm: float
    Horizontal_Distance_To_Fire_Points: float
    Wilderness_Area: str
    Soil_Type: str
    # ‚ö†Ô∏è Cover_Type (target) no se incluye porque es lo que vamos a predecir

# --------------------------------------------------
# Configuraci√≥n de MLflow (placeholder hasta entrenar)
# --------------------------------------------------
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
MODEL_NAME = os.getenv("MODEL_NAME", "cover_type_model")   # nombre que usaremos al registrar
MODEL_STAGE = os.getenv("MODEL_STAGE", "Production")       # stage a servir (Staging/Production)

# Inicialmente no cargamos modelo (se conecta despu√©s al Registry)
model = None

# --------------------------------------------------
# Endpoints
# --------------------------------------------------
@app.get("/health")
def health():
    """Verifica que el servicio est√° activo"""
    return {"status": "ok"}

@app.post("/predict")
def predict(row: InputRow):
    """Predice la clase Cover_Type para un registro"""
    data = pd.DataFrame([row.dict()])

    if model is None:
        return {
            "prediction": None,
            "detail": f"Modelo '{MODEL_NAME}' en stage '{MODEL_STAGE}' a√∫n no cargado."
        }

    try:
        pred = model.predict(data)
        return {"prediction": int(pred[0])}
    except Exception as e:
        return {"error": str(e)}
```

crear dockerfile:

```dockerfile
FROM python:3.11-slim

# Configuraci√≥n de entorno
ENV PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# Crear directorio de trabajo
WORKDIR /app

# Copiar dependencias primero (para cachear instalaci√≥n)
COPY requirements.txt .

# Instalar dependencias
RUN pip install --upgrade pip && pip install -r requirements.txt

# Copiar c√≥digo de la aplicaci√≥n
COPY . .

# Exponer puerto
EXPOSE 8000

# Comando de arranque (Uvicorn servidor ASGI)
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]

```

El docker-compose.yml que armamos es el coraz√≥n de tu infraestructura MLOps: ah√≠ se definen todos los servicios que se levantan como contenedores, c√≥mo se conectan y qu√© rol cumplen.
Te lo explico servicio por servicio:
üóÑÔ∏è MySQL
mysql:
  image: mysql:8.0
  environment:
    MYSQL_ROOT_PASSWORD: root
  volumes:
    - ./mysql_data:/var/lib/mysql
    - ./configs/mysql-init.sql:/docker-entrypoint-initdb.d/mysql-init.sql:ro
Corre un contenedor con MySQL 8.0.
Guarda sus datos en ./mysql_data (persistencia local).
Ejecuta al arranque mysql-init.sql ‚Üí crea la base mlflow y el usuario mlflow/mlflow.
üëâ Funci√≥n: es el backend de metadatos tanto para MLflow (experimentos, runs) como para Airflow (su metastore).
‚òÅÔ∏è MinIO
minio:
  image: minio/minio:latest
  environment:
    MINIO_ROOT_USER: minioadmin
    MINIO_ROOT_PASSWORD: minioadmin
  command: server /data --console-address ":9001"
  ports:
    - "9000:9000"
    - "9001:9001"
Almac√©n de objetos estilo Amazon S3, pero local.
Expuesto en:
9000 ‚Üí API S3 (donde MLflow guarda artefactos).
9001 ‚Üí consola web (UI de MinIO).
üëâ Funci√≥n: es donde MLflow guarda los modelos entrenados y otros artefactos (plots, datasets, etc.).
üìä MLflow
mlflow:
  build: ./mlflow
  command: >
    server --host 0.0.0.0 --port 5000
    --backend-store-uri mysql+pymysql://mlflow:mlflow@mysql:3306/mlflow
    --artifacts-destination s3://mlflow
Corre MLflow Tracking Server en el puerto 5000.
Usa MySQL como backend de metadatos.
Usa MinIO como artifact store (s3://mlflow).
üëâ Funci√≥n: guarda par√°metros, m√©tricas y modelos de cada entrenamiento ‚Üí y act√∫a como Model Registry.
‚ö° FastAPI
fastapi:
  build: ./fastapi
  environment:
    MLFLOW_TRACKING_URI: http://mlflow:5000
    MODEL_NAME: cover_type_model
    MODEL_STAGE: Production
Servicio REST de inferencia.
Construido con tu fastapi/app.py.
Conectado a MLflow (sabe qu√© modelo cargar desde el Model Registry).
Expone 8000 ‚Üí accesible en http://localhost:8000.
üëâ Funci√≥n: sirve el √∫ltimo modelo promovido a Production.
üåÄ Airflow
airflow:
  image: apache/airflow:2.8.1
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: mysql+mysqldb://mlflow:mlflow@mysql:3306/mlflow
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
  ports:
    - "8080:8080"
Corre Airflow Webserver + Scheduler.
Usa MySQL como metastore.
Monta tus DAGs locales en /opt/airflow/dags.
Expuesto en 8080 ‚Üí accesible en http://localhost:8080.
üëâ Funci√≥n: orquesta el pipeline de ingesta de datos ‚Üí preprocesamiento ‚Üí entrenamiento ‚Üí registro en MLflow.
üì¶ Vol√∫menes
volumes:
  minio_data:
Persistencia de datos de MinIO.
As√≠, si paras el stack, los modelos guardados no se pierden.
üéØ En resumen
MySQL ‚Üí metadatos (MLflow + Airflow).
MinIO ‚Üí artefactos pesados (modelos, datasets).
MLflow ‚Üí tracking + registro de modelos.
FastAPI ‚Üí servicio de inferencia en producci√≥n.
Airflow ‚Üí orquestador de todo el flujo (ingesta ‚Üí entrenamiento ‚Üí registro).
Todo conectado en un solo docker-compose.yml ‚Üí simulando un ecosistema de producci√≥n en miniatura üè≠.